{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/christof/code/tm-mlops-workshop/mlflow_tutorial/notebooks/mlruns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a toy dataset from sklearn\n",
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's quickly split the dataset\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's possible to define the schema for input/output\n",
    "# This will be visualized within the mlflow ui\n",
    "# To define the schema in your trained model you should save the model explicitly turning off the autosave (log_models=False)\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"age\"),\n",
    "  ColSpec(\"double\", \"sex\"),\n",
    "  ColSpec(\"double\", \"bmi\"),\n",
    "  ColSpec(\"double\", \"bp\"),\n",
    "  ColSpec(\"double\", \"s1\"),\n",
    "  ColSpec(\"double\", \"s2\"),\n",
    "  ColSpec(\"double\", \"s3\"),\n",
    "  ColSpec(\"double\", \"s4\"),\n",
    "  ColSpec(\"double\", \"s5\"),\n",
    "  ColSpec(\"double\", \"s6\"),\n",
    "])\n",
    "\n",
    "output_schema = Schema([ColSpec(\"long\", \"target\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recommended way to get started using MLflow tracking with Python is to use the MLflow autolog() API.\n",
    "# With MLflowâ€™s autologging capabilities, a single line of code automatically logs the resulting model \n",
    "# the parameters used to create the model, and a model score.\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# This time we will use a specific experiment\n",
    "# If you use databricks the name should be a filesystem path, so use a / before the name\n",
    "mlflow.set_experiment(\"Diabetes ML Experiment\")\n",
    " \n",
    "# With autolog() enabled, all model parameters, a model score, and the fitted model are automatically logged.\n",
    "# It's also possible to pass a run name like  mlflow.start_run(run_name=\"My amazing run\"), otherwise MLflow will choose one for us \n",
    "with mlflow.start_run():\n",
    "  # Set the model parameters. \n",
    "  n_estimators = 10\n",
    "  max_depth = 5\n",
    "  max_features = 3\n",
    "\n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  # Use the model to make predictions on the test dataset.\n",
    "  predictions = rf.predict(X_test)\n",
    "\n",
    "  # Log the model parameters used for this run.\n",
    "  mlflow.log_param(\"num_trees\", n_estimators)\n",
    "  mlflow.log_param(\"maxdepth\", max_depth)\n",
    "  mlflow.log_param(\"max_feat\", max_features)\n",
    "\n",
    "  # Define a metric to use to evaluate the model.\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "    \n",
    "  # Log the value of the metric from this run.\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "  # We can even explicitly log the model created by this run with its signature\n",
    "  mlflow.sklearn.log_model(rf, \"model\", signature=signature)\n",
    "\n",
    "  # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "  df = pd.DataFrame(data = predictions - y_test)\n",
    "  # Create a plot of residuals\n",
    "  plt.plot(df)\n",
    "  plt.xlabel(\"Observation\")\n",
    "  plt.ylabel(\"Residual\")\n",
    "  plt.title(\"Residuals\")\n",
    "\n",
    "  # Save the plot figure\n",
    "  fig = plt.gcf()\n",
    "  mlflow.log_figure(fig, \"residuals_plot.png\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model locally\n",
    "# Change the run-id\n",
    "! mlflow models serve --env-manager=local -m runs:/<run-id>/model -p 5001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
